# Multi-Modal Data Fusion - Project Work: Multi-Modal Physical Exercise Classification

## Overview
This project is a part of the Master's Level Course called **Multi-Modal Data Fusion** taught at the **University of Oulu**. The aim of this project is to explore and implement various techniques for recognizing physical exercises using multi-modal data collected from wearable sensors and depth cameras.

## Dataset
The dataset used in this project is the **MEx dataset**, which consists of data collected from multiple subjects performing various physical exercises. The dataset includes measurements from an accelerometer attached to the subject's thigh and depth camera recordings. The exercises were performed while the subjects were lying down on a mat. 

The original dataset contains data from 30 subjects, but this project utilizes a subset of 10 subjects. The dataset is designed to facilitate user-independent classification of physical exercises.

For more information and to access the dataset, please visit the following link: [MEx Dataset](https://archive.ics.uci.edu/dataset/500/mex).
